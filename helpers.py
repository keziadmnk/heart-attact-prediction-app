# helpers.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO
from matplotlib.backends.backend_pdf import PdfPages

from sklearn.metrics import confusion_matrix  # (opsional) untuk tipe/utility confusion matrix jika dibutuhkan

# --- KONSTANTA TARGET ---
# Nama kolom target (label) di dataset untuk serangan jantung
TARGET_COL = "heart_attack"


# --- HELPER: CEK DATA RAW ---
def require_raw_data():
    """
    Mengecek apakah dataset mentah (raw_df) sudah ada di session_state.
    Jika belum ada, tampilkan peringatan dan hentikan eksekusi halaman.
    """
    if st.session_state.get("raw_df") is None:
        st.warning("âš ï¸ Silakan upload dataset terlebih dahulu di menu **Upload Dataset**.")
        st.info("ðŸ“Œ Gunakan menu sidebar di kiri untuk mengakses fitur aplikasi secara berurutan.")
        st.stop()


# --- HELPER: CEK DATA BERSIH ---
def require_clean_data():
    """
    Mengecek apakah data yang sudah di-preprocess (clean_df) tersedia.
    Jika belum, user diminta menjalankan preprocessing terlebih dahulu.
    """
    if st.session_state.get("clean_df") is None:
        st.warning("âš ï¸ Silakan lakukan preprocessing data terlebih dahulu di menu **Preprocessing Data**.")
        st.info("ðŸ“Œ Gunakan menu sidebar di kiri untuk mengakses fitur aplikasi secara berurutan.")
        st.stop()


# --- HELPER: CEK MODEL ---
def require_model():
    """
    Mengecek apakah model Random Forest sudah dilatih dan disimpan di session_state.
    Jika belum, user diarahkan untuk melakukan training di menu Analisis Data.
    """
    if st.session_state.get("rf_model") is None:
        st.warning("âš ï¸ Model belum dilatih. Silakan lakukan training di menu **Analisis Data**.")
        st.info("ðŸ“Œ Gunakan menu sidebar di kiri untuk mengakses fitur aplikasi secara berurutan.")
        st.stop()


# --- HELPER: PREPROCESSING DATA ---
def preprocess_data(df: pd.DataFrame):
    """
    Melakukan preprocessing data:
    - Memastikan semua kolom fitur + target tersedia
    - Mengambil hanya kolom yang dibutuhkan
    - Menghapus baris duplikat
    - Menghapus baris dengan nilai missing
    - Mengonversi kolom bertipe object menjadi kode kategori (numerik)
    Mengembalikan:
    - df yang sudah bersih
    - info ringkasan proses preprocessing (dict)
    """
    df = df.copy()  # buat salinan agar tidak mengubah dataframe asli

    # daftar kolom yang wajib ada (fitur + target)
    all_cols = st.session_state["features"] + [TARGET_COL]

    # cek apakah ada kolom yang hilang
    missing = [c for c in all_cols if c not in df.columns]
    if missing:
        st.error(f"âŒ Kolom berikut tidak ditemukan di dataset: {missing}")
        st.stop()

    # ambil hanya kolom yang dibutuhkan
    df = df[all_cols]

    # simpan informasi awal sebelum dibersihkan
    rows_before = df.shape[0]          # jumlah baris sebelum preprocessing
    dup_count = df.duplicated().sum()  # jumlah baris duplikat
    missing_before = df.isna().sum()   # jumlah missing per kolom

    # hapus baris duplikat
    df = df.drop_duplicates()
    # hapus baris yang mengandung missing values
    df = df.dropna()

    # konversi kolom bertipe object -> kode kategori (numerik)
    for col in df.columns:
        if df[col].dtype == "object":
            df[col] = df[col].astype("category").cat.codes

    # ringkasan info preprocessing untuk ditampilkan di UI
    info = {
        "rows_before": int(rows_before),                 # baris sebelum preprocessing
        "rows_after": int(df.shape[0]),                  # baris setelah preprocessing
        "cols": int(df.shape[1]),                        # jumlah kolom aktif
        "duplicates_removed": int(dup_count),            # jumlah duplikat yang dihapus
        "missing_values_before": missing_before.to_dict(),  # missing value per kolom (sebelum)
        "missing_total_after": int(df.isna().sum().sum()),  # total missing setelah preprocessing (harusnya 0)
    }

    return df, info


# --- HELPER: CONFUSION MATRIX PLOT ---
def plot_confusion_matrix(cm, labels):
    """
    Membuat visualisasi confusion matrix dalam bentuk heatmap,
    lalu menampilkannya di Streamlit.
    Parameter:
    - cm     : matriks kebingungan (2x2 untuk binary classification)
    - labels : label untuk axis (list of string)
    """
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(
        cm,
        annot=True,       # tampilkan nilai di tiap sel
        fmt="d",          # format integer
        cmap="Reds",      # warna merah
        cbar=True,        # tampilkan colorbar
        ax=ax,
        square=True,
        linewidths=1,
        linecolor="white",
    )
    ax.set_xlabel("Predicted", fontsize=12, fontweight="bold")  # label sumbu X
    ax.set_ylabel("Actual", fontsize=12, fontweight="bold")     # label sumbu Y
    ax.set_xticklabels(labels, fontsize=10)                     # label kelas pada sumbu X
    ax.set_yticklabels(labels, fontsize=10)                     # label kelas pada sumbu Y
    ax.set_title("Confusion Matrix", fontsize=14, fontweight="bold", pad=20)
    plt.tight_layout()
    st.pyplot(fig)  # render plot ke aplikasi Streamlit
    return fig      # kembalikan figure (kalau mau dipakai di tempat lain, mis. simpan ke PDF)


# --- HELPER: FEATURE IMPORTANCE ---
def plot_feature_importance(model, feature_names):
    """
    Menampilkan 10 fitur teratas berdasarkan nilai feature_importances_ dari model Random Forest.
    Parameter:
    - model         : model yang sudah dilatih (punya atribut feature_importances_)
    - feature_names : list nama fitur sesuai urutan kolom X saat training
    """
    importances = model.feature_importances_
    idx = np.argsort(importances)[-10:]  # ambil index 10 fitur dengan importance terbesar
    sorted_features = np.array(feature_names)[idx]      # nama fitur yang sudah diurutkan
    sorted_importances = importances[idx]              # nilai importance yang sudah diurutkan

    fig, ax = plt.subplots(figsize=(10, 6))
    colors = plt.cm.Reds(np.linspace(0.4, 0.8, len(sorted_features)))
    ax.barh(sorted_features, sorted_importances, color=colors)  # bar horizontal
    ax.set_title(
        "Top 10 Feature Importance - Random Forest",
        fontsize=14,
        fontweight="bold",
        pad=20,
    )
    ax.set_xlabel("Importance Score", fontsize=12, fontweight="bold")
    ax.set_ylabel("Features", fontsize=12, fontweight="bold")
    plt.tight_layout()
    st.pyplot(fig)  # tampilkan di Streamlit
    return fig      # kembalikan figure


# --- HELPER: GENERATE PDF VISUALISASI ---
def generate_pdf_visualizations(df: pd.DataFrame, model):
    """
    Membuat file PDF yang berisi beberapa visualisasi:
    1. Distribusi usia
    2. Distribusi label serangan jantung (target)
    3. Heatmap korelasi antar fitur
    4. (Opsional) Feature importance dari model Random Forest jika model tersedia
    Mengembalikan:
    - buffer BytesIO yang berisi isi file PDF, siap untuk di-download.
    """
    buf = BytesIO()  # buffer di memori sebagai pengganti file fisik

    # PdfPages akan menyimpan setiap figure yang disimpan (pdf.savefig) ke dalam satu PDF
    with PdfPages(buf) as pdf:
        # Plot 1: Age Distribution
        fig1, ax1 = plt.subplots(figsize=(10, 6))
        sns.histplot(df["age"], kde=True, ax=ax1, bins=20, color="#8B0000")
        ax1.set_title("Distribusi Usia", fontsize=14, fontweight="bold")
        ax1.set_xlabel("Usia (tahun)", fontsize=12)
        ax1.set_ylabel("Frekuensi", fontsize=12)
        plt.tight_layout()
        pdf.savefig(fig1)  # simpan figure ke PDF
        plt.close(fig1)    # tutup figure agar tidak menumpuk di memori

        # Plot 2: Heart Attack Distribution
        fig2, ax2 = plt.subplots(figsize=(8, 6))
        heart_attack_counts = df[TARGET_COL].value_counts()
        colors = ["#28a745", "#8B0000"]  # hijau = tidak, merah = ya
        ax2.bar(heart_attack_counts.index, heart_attack_counts.values, color=colors)
        ax2.set_title("Distribusi Label Serangan Jantung", fontsize=14, fontweight="bold")
        ax2.set_xlabel("Label", fontsize=12)
        ax2.set_ylabel("Jumlah", fontsize=12)
        ax2.set_xticks([0, 1])
        ax2.set_xticklabels(["Tidak (0)", "Ya (1)"])
        plt.tight_layout()
        pdf.savefig(fig2)
        plt.close(fig2)

        # Plot 3: Correlation Heatmap
        fig3, ax3 = plt.subplots(figsize=(12, 10))
        corr = df.corr()  # korelasi antar semua kolom numerik
        sns.heatmap(
            corr,
            cmap="Reds",
            ax=ax3,
            annot=False,
            square=True,
            linewidths=0.5,
            cbar_kws={"shrink": 0.8},
        )
        ax3.set_title("Heatmap Korelasi Fitur", fontsize=14, fontweight="bold")
        plt.tight_layout()
        pdf.savefig(fig3)
        plt.close(fig3)

        # Plot 4: Feature Importance (jika model punya feature_importances_)
        if model is not None and hasattr(model, "feature_importances_"):
            fig4, ax4 = plt.subplots(figsize=(10, 8))
            importances = model.feature_importances_
            idx = np.argsort(importances)  # urutkan semua fitur
            sorted_features = np.array(st.session_state["features"])[idx]
            sorted_importances = importances[idx]
            colors = plt.cm.Reds(np.linspace(0.4, 0.8, len(sorted_features)))
            ax4.barh(sorted_features, sorted_importances, color=colors)
            ax4.set_title("Feature Importance - Random Forest", fontsize=14, fontweight="bold")
            ax4.set_xlabel("Importance Score", fontsize=12)
            plt.tight_layout()
            pdf.savefig(fig4)
            plt.close(fig4)

    # reset pointer buffer ke awal supaya bisa dibaca/di-download
    buf.seek(0)
    return buf
